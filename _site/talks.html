<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Talks | CMCL 2025</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Talks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The 2025 Cognitive Modeling and Computational Linguistics workshop." />
<meta property="og:description" content="The 2025 Cognitive Modeling and Computational Linguistics workshop." />
<link rel="canonical" href="http://localhost:4000/talks" />
<meta property="og:url" content="http://localhost:4000/talks" />
<meta property="og:site_name" content="CMCL 2025" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Talks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"The 2025 Cognitive Modeling and Computational Linguistics workshop.","headline":"Talks","url":"http://localhost:4000/talks"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="CMCL 2025" /></head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">CMCL 2025</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/CfP">Call for Papers</a><a class="page-link" href="/program">Program</a><a class="page-link" href="/talks">Talks</a><a class="page-link" href="/organizers">Organizers</a><a class="page-link" href="/registration">Registration</a><a class="page-link" href="/code-of-conduct">Code of Conduct</a><a class="page-link" href="/previous_cmcls">Past CMCLs</a></div>
      </nav></div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Talks</h1>
  </header>

  <div class="post-content">
    <p>For the CMCL 2025 edition, we are glad to have invited speakers, each bringing complementary backgrounds and expertise.</p>

<h2 id="tessa-verhoef-leiden-institute-of-advanced-computer-science"><strong>Tessa Verhoef</strong> (Leiden Institute of Advanced Computer Science)</h2>
<p>Title: <em>The emergence of language universals in neural agents and vision-and-language models</em></p>
<h3 id="abstract">Abstract</h3>
<p>Human cognition constrains how we communicate. Our cognitive biases and preferences interact with the processes that drive language emergence and change in non-trivial ways. A powerful method to discern the roles of cognitive biases and processes like language learning and use in shaping linguistic structure is to build agent-based models. Recent advances in computational linguistics and deep learning sparked a renewed interest in such simulations, creating the opportunity to model increasingly realistic phenomena. These models simulate emergent communication, referring to the spontaneous development of a communication system through repeated interactions between individual neural network agents. However, a crucial challenge in this line of work is that such artificial learners still often behave differently from human learners. Directly inspired by human artificial language learning studies, we proposed a novel framework for simulating language learning and change, which allows agents to first learn an artificial language and then use it to communicate, with the aim of studying the emergence of specific linguistic properties. I will show how we used it to simulate the emergence of a well-known language phenomenon: the word-order/case-marking trade-off. I will also share some recent findings where we test for the presence of a well-known human cross-modal mapping preference (the bouba-kiki effect) in vision-and-language models. Cross-modal associations play an essential role in human language understanding, learning, and evolution, but our findings reveal that multimodal language models do not align well with such human preferences. Finally, I will provide a sneak peek at new findings that reveal what a novel artificial language looks like when it has emerged to adapt to preferences of both humans and LLMs in a hybrid language game experiment.</p>

<h3 id="bio">Bio</h3>
<p>Tessa Verhoef is an Assistant Professor at the Leiden Institute of Advanced Computer Science (LIACS) where she leads the Emergent Communication Group, co-founded the Creative Intelligence Lab and conducts interdisciplinary research at the intersection of language, cognition, cultural evolution and computation. She is deeply interested in the natural mechanisms that support the emergence of novel communication systems among groups of humans, computational agents, or between human and machine. Before joining Leiden University, she was a postdoc at the University of California, San Diego (UCSD), where she conducted her NWO Rubicon research at the Center for Research in Language (CRL) and became a Frontiers of Innovation Scholars Program (FISP) fellow at the departments of Communication and Electrical and Computer Engineering. She has a BSc and MSc in Artificial Intelligence, and obtained her PhD in Language Evolution at the University of Amsterdam.</p>

<h2 id="john-t-hale-johns-hopkins-university"><strong>John T. Hale</strong> (Johns Hopkins University)</h2>
<p>Title: <em>Towards mechanistic explanation of human language processing</em></p>
<h3 id="abstract-1">Abstract</h3>
<p>Cognitive models of human language hold out the hope of explaining how comprehension works. We hope for a process model that is intelligible to scientists and relates, in some systematic way, to the human brain. What sorts of mechanisms offer such explanation? The talk reviews candidate mechanisms of transition-based incremental parsing. Such mechanisms explicitly decide, for instance, when a word serves as a direct object of a verb. The talk makes the case for building-in this sort of interpretabilty from the start. Doing so, we gain scientific leverage on classic questions about the human sentence processing mechanism: (1) does the parser hedge its bets and (2) what is a “wrong choice”?</p>

<h3 id="bio-1">Bio</h3>
<p>John Hale started CMCL in 2010. He is currently visiting Johns Hopkins University while on leave from the University of Georgia. He also serves as a Research Scientist with Google DeepMind. He previously taught at Cornell University
and Michigan State University. He is the author of <a href="https://web.stanford.edu/group/cslipublications/cslipublications/site/9781575867472.shtml">“Automaton Theories of Human Sentence Comprehension”</a>.</p>


  </div>

</article>

      </div>
    </main>

    <footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">CMCL 2025</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">CMCL 2025</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The 2025 Cognitive Modeling and Computational Linguistics workshop.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
