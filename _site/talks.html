<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Talks | CMCL 2024</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Talks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The 2024 Cognitive Modeling and Computational Linguistics workshop." />
<meta property="og:description" content="The 2024 Cognitive Modeling and Computational Linguistics workshop." />
<link rel="canonical" href="http://localhost:4001/talks" />
<meta property="og:url" content="http://localhost:4001/talks" />
<meta property="og:site_name" content="CMCL 2024" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Talks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"The 2024 Cognitive Modeling and Computational Linguistics workshop.","headline":"Talks","url":"http://localhost:4001/talks"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4001/feed.xml" title="CMCL 2024" /></head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">CMCL 2024</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/CfP">Call for Papers</a><a class="page-link" href="/program">Program</a><a class="page-link" href="/talks">Talks</a><a class="page-link" href="/organizers">Organizers</a><a class="page-link" href="/registration">Registration</a><a class="page-link" href="/code-of-conduct">Code of Conduct</a><a class="page-link" href="/previous_cmcls">Past CMCLs</a></div>
      </nav></div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Talks</h1>
  </header>

  <div class="post-content">
    <h2 id="invited-speakers">Invited Speakers</h2>

<h3 id="invited-speaker-1-sandro-pezzelle">Invited Speaker 1: Sandro Pezzelle</h3>
<p>Title: <strong>From semantic understanding to human-like communication: Implicit and underspecified language as a testbed for large language models</strong></p>

<p>Abstract: The language we use in everyday communicative contexts exhibits a variety of phenomena—such as ambiguity, missing information, or semantic features expressed only indirectly—that make it often implicit or underspecified. Despite this, people are good at understanding and interpreting it. This is possible because we can exploit additional information from the linguistic or extralinguistic context and shared or prior knowledge. Given the ubiquity of these phenomena, NLP models must handle them appropriately to communicate effectively with users and avoid biased behavior, that can be potentially harmful. In this talk, I will present recent work from my group investigating how state-of-the-art transformer large language models (LLMs) handle these phenomena. In particular, I will focus on the understanding of sentences with atypical animacy (“a peanut fell in love”) and on the interpretation of sentences that are ambiguous (“Bob looked at Sam holding a yellow bag”) or where some information is missing or implicit (“don’t spend too much”). I will show that, in some cases, LMs behave surprisingly similarly to speakers; in other cases, they fail quite spectacularly. I will argue that having access to multimodal information (e.g., from language and vision) should, in principle, give these models an advantage on these semantic phenomena—as long as we take a perspective aware of the communicative aspects of language use.</p>

<p>Bio: Sandro Pezzelle (<a href="https://sandropezzelle.github.io/">https://sandropezzelle.github.io/</a>) studies human-like natural language understanding and generation in text-only large language models (LLMs) and their multimodal versions combining language-and-vision  (VLMs). As such, his work combines methods and insights from Natural Language Processing, Computer Vision, and Cognitive Science. His current research interests span LLM and VLM evaluation and interpretability inspired by human cognition, how the learning of semantic and pragmatic abilities compares in humans and machines, and whether (and how) the cognitive mechanisms underlying human language communication can be used to develop better language models. He co-authored articles in top-tier conferences (ACL, EMNLP, EACL, NAACL, CoLM) and journals (TACL, Cognition, Cognitive Science). He is a member of the ELLIS society, a faculty member of the ELLIS Amsterdam Unit, and a board member of SigSem, the ACL special interest group in computational semantics. In 2024, he organized the UnImplicit workshop at EACL 2024 on understanding implicit and underspecified language.</p>

<!--![](/assets/img/PW.jpeg){: style="float: left; margin-right: 1em;"}-->
<h3 style="clear: left" id="invited-speaker-2-frank-keller">Invited Speaker 2: Frank Keller</h3>
<p>Title: <strong>Predicting Human Sentence Production across Modalities and Languages</strong><br />
Joint work with Moreno I. Coco, Eunice G. Fernandes, and Manabu Arai</p>

<p>Slides: you can <a href="http://localhost:4001/assets/cmcl_slides_keller.pdf">get the PDF</a> here.</p>

<p>Abstract: Human cognition is a highly integrated system which synchronizes
processes and representations across modalities. Previous research on
the synchronization between attention and sentence production
demonstrated that similar scene descriptions correspond to similar
sequences of attended objects (scan patterns). In this work, we
investigate whether this finding generalizes from English to languages
with different word order. We test whether synchronicity holds not
just within a language but across languages and examine the relative
contribution of syntax and semantics. Three groups of participants
speaking English, Portuguese, or Japanese described objects situated
in a visual scene, while being eye-tracked. Across all participants,
pair-wise sentence similarity was computed using Universal Sentence
Encoder, which generates multilingual vector-based meaning
representations. Part-of-Speech (PoS) sequences were assigned to the
produced sentences and similarities between PoS sequences and scan
patterns were measured using Longest Common Subsequence. We found that
similar sentences are associated with similar scan patterns in all
three languages. Moreover, we demonstrated for the first time that
this relationship holds across languages (e.g., if a Japanese and a
Portuguese sentence are semantically similar, their associated scan
patterns are also similar). In contrast, we find that syntactic
similarity (i.e., PoS similarity) is predicted by scan patterns only
within the same scene and only between languages with similar word
order. This confirms that visual attention and language production are
synchronized across language and modalities and points to a grammar of
perception that is language-independent, goes beyond syntactic
realizations, and manifests as oculomotor responses such as
eye-movements.</p>

<p>Bio: Frank Keller is a professor in the School of Informatics at the
University of Edinburgh. He has also held visiting positions at MIT
and the University of Washington. His research area is natural
language processing, with a particular focus on language and vision
tasks, such as image description, visual grounding, video
summarization, and visual story telling. His second main research
interest is computational narrative, where he works on modeling key
narrative concepts such as characters, plot turning points, and
suspense. This involves understanding or generating long-form texts
such as movie scripts or books, which is challenging for LLMs.</p>

<p style="clear: left">Prof. Keller is part of the leadership team of the UKRI Centre for
Doctoral Training in Natural Language Processing; he serves on the
editorial board of the Transactions of the ACL, and he is an ELLIS
fellow. In the past, he has held an ERC grant in the area of language
and vision.
<b>Frank Keller</b> (<a href="https://homepages.inf.ed.ac.uk/keller/">https://homepages.inf.ed.ac.uk/keller/</a>) is a professor in the School of Informatics at the University of Edinburgh.</p>

<h3 id="invited-speaker-3-aida-nematzadeh">Invited Speaker 3: Aida Nematzadeh</h3>
<p>Title: <strong>Leveraging Cognitive Science to Unravel the Complexities of
Generative Models</strong></p>

<p>Slides: you can <a href="http://localhost:4001/assets/CMCL2024_Leveraging_Cognitive_Science_to_Unravel_the_Complexities_of_Generative_Models.pdf">get the PDF</a> here</p>

<p>Abstract: Recent generative models have demonstrated remarkable
capabilities, from solving intricate reasoning problems to creating
highly realistic images. However, as these models grow more complex,
evaluating them presents increasing challenges—particularly since we
often have access only to their outputs, not the underlying
mechanisms. This predicament mirrors a challenge faced by cognitive
scientists: understanding human cognition by observing behavior
without direct access to the “cognitive model” itself. In this talk, I
will explore how principles from cognitive science can illuminate the
evaluation of generative models. I will discuss how cognitive science
approaches, such as experimental design in human data collection,
probing for specific capabilities, and developing automated evaluation
metrics, can offer valuable insights into understanding and assessing
these advanced models.</p>

<p>Bio: Aida Nematzadeh (<a href="http://www.aidanematzadeh.me/">http://www.aidanematzadeh.me/</a>) is a Research Scientist at DeepMind, where she
explores the intersection of computational linguistics, cognitive
science, and machine learning. Her recent work focuses on multimodal
learning, as well as the evaluation and analysis of neural
representations. Prior to joining DeepMind, Aida was a postdoctoral
researcher at UC Berkeley. She holds a PhD and an MSc in Computer
Science from the University of Toronto.</p>


  </div>

</article>

      </div>
    </main>

    <footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">CMCL 2024</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">CMCL 2024</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The 2024 Cognitive Modeling and Computational Linguistics workshop.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
